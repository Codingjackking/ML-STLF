{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "\n",
    "# Load data\n",
    "file_path = 'data/enepk_report.xlsx'\n",
    "# data = pd.read_excel(file_path)\n",
    "data = pd.read_excel(file_path, header=[0, 1, 2])\n",
    "\n",
    "# Flatten multi-level columns\n",
    "data.columns = data.columns.map(' '.join).str.strip()\n",
    "\n",
    "# Display the columns to identify the unnecessary ones\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the plots\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Function to calculate MBD\n",
    "def mean_bias_deviation(y_true, y_pred):\n",
    "    return np.mean(y_true - y_pred)\n",
    "\n",
    "# Function to calculate sMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred) / ((np.abs(y_true) + np.abs(y_pred)) / 2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add noise to the features\n",
    "def add_noise(features, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, features.shape)\n",
    "    return features + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Pct Chg Month Unnamed: 26_level_2', \n",
    "    'Pct Chg Year Unnamed: 27_level_2', \n",
    "    'Pct Chg Year Revisions', \n",
    "    'Pct Chg Year Remarks'\n",
    "]\n",
    "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Rename columns for easier access\n",
    "column_names = [\n",
    "    'Year', 'Month', 'Actual NEL (GWh)', 'Pct Chg Month Prior Yr', 'Y-T-D NEL (GWh)', 'Y-T-D Pct Chg Prior Yr', \n",
    "    '12 Mo Rolling NEL (GWh)', 'Pct Chg 12-Mo Roll Prior Yr', 'Pct Chg Normalized NEL (GWh)', 'Pct Chg Normal Prior Yr', \n",
    "    'Y-T-D Normal (GWh)', 'Pct Chg Y-T-D Prior Yr', '12 Month Rolling Normal GWh', 'Pct Chg 12-Mo Roll Prior Yr.1', \n",
    "    'Pct Chg Monthly tCDD', 'Pct Chg Monthly HDD', 'Total Adjmnts GWh', 'Weather Adjmnt GWh', 'NonH-Wdys adj', \n",
    "    'Leap Year Adj.', 'Monthly Peak MW', 'Pct Chg Peak Prior Year', 'Pct Chg Pk Date', 'Pct Chg Pk Hour', 'Pct Chg Pk Temp', 'Pct Chg Pk DPt'\n",
    "]\n",
    "\n",
    "# Ensure the number of columns matches\n",
    "if len(column_names) == len(data.columns):\n",
    "    data.columns = column_names\n",
    "else:\n",
    "    print(f\"Column length mismatch: Expected {len(column_names)} columns, but got {len(data.columns)} columns\")\n",
    "\n",
    "# Convert data types\n",
    "data['Year'] = pd.to_numeric(data['Year'], errors='coerce')\n",
    "\n",
    "# Convert month names to numeric\n",
    "month_map = {'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6, 'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12}\n",
    "data['Month'] = data['Month'].map(month_map)\n",
    "\n",
    "# Set datetime index\n",
    "data['Date'] = pd.to_datetime(data[['Year', 'Month']].assign(DAY=1))\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# # Creating Static Feature\n",
    "# data['Leap Year Adj.'] = data['Year'].apply(lambda x: 1 if x % 4 == 0 and (x % 100 != 0 or x % 400 == 0) else 0)\n",
    "\n",
    "# # Creating Lag Features\n",
    "# data['Actual_NEL_Lag1'] = data['Actual NEL (GWh)'].shift(1)\n",
    "# data['Actual_NEL_Lag2'] = data['Actual NEL (GWh)'].shift(2)\n",
    "# data['Monthly_Peak_Lag1'] = data['Monthly Peak MW'].shift(1)\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna(subset=['Year', 'Month'])\n",
    "# data = data.dropna(subset=['Year', 'Month', 'Actual NEL (GWh)', 'Actual_NEL_Lag1', 'Actual_NEL_Lag2', 'Monthly_Peak_Lag1', 'Leap Year Adj.'])\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available features\n",
    "# Original Feature\n",
    "# features = ['Year', 'Month', 'Actual NEL (GWh)', 'Monthly Peak MW', 'Total Adjmnts GWh', 'Weather Adjmnt GWh']  \n",
    "\n",
    "# Optimal Feature\n",
    "features = ['Year', 'Month', 'Actual NEL (GWh)', 'Monthly Peak MW', 'Total Adjmnts GWh']\n",
    "\n",
    "# Update with Lag and Static Feature\n",
    "# features = [\n",
    "#     'Year', 'Month', 'Actual NEL (GWh)', 'Monthly Peak MW', \n",
    "#     'Total Adjmnts GWh', 'Leap Year Adj.',\n",
    "#     'Actual_NEL_Lag1', 'Actual_NEL_Lag2', 'Monthly_Peak_Lag1'\n",
    "# ]\n",
    "target = 'Actual NEL (GWh)'\n",
    "\n",
    "# Split data based on years\n",
    "# train_data = data[(data['Year'] >= 2015) & (data['Year'] <= 2017)]\n",
    "# val_data = data[data['Year'] == 2018]\n",
    "# test_data = data[data['Year'] == 2019]\n",
    "\n",
    "# Train data: 2013-2017\n",
    "train_data = data[(data['Year'] >= 2013) & (data['Year'] <= 2017)]\n",
    "# Validation data: 2018\n",
    "val_data_single = data[data['Year'] == 2018]\n",
    "# Validation data: 2018 and 2020\n",
    "val_data_multi = data[(data['Year'] == 2018) | (data['Year'] == 2020)]\n",
    "# Test data - Single-Year Test Set: 2019\n",
    "test_data_single = data[data['Year'] == 2019]\n",
    "# Test data - Multi-Year Test Set: 2019, 2021, 2022\n",
    "test_data_multi = data[(data['Year'] == 2019) | (data['Year'] == 2021) | (data['Year'] == 2022)]\n",
    "\n",
    "# Print the number of data points\n",
    "print(f\"Training Data Points: {len(train_data)}\")\n",
    "print(f\"Validation Data Points: {len(val_data_single)}\")\n",
    "print(f\"Validation Data Points: {len(val_data_multi)}\")\n",
    "print(f\"Test Data Points: {len(test_data_single)}\")\n",
    "print(f\"Test Data Points: {len(test_data_multi)}\")\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "X_val_single = val_data_single[features]\n",
    "y_val_single = val_data_single[target]\n",
    "\n",
    "X_val_multi = val_data_multi[features]\n",
    "y_val_multi= val_data_multi[target]\n",
    "\n",
    "X_test_single = test_data_single[features]\n",
    "y_test_single = test_data_single[target]\n",
    "\n",
    "X_test_multi = test_data_multi[features]\n",
    "y_test_multi = test_data_multi[target]\n",
    "\n",
    "# # error_correction_train_data = data[data['Year'] == 2018]\n",
    "\n",
    "# Further split 2018 data for error correction module\n",
    "# error_correction_train, error_correction_val = train_test_split(error_correction_train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for NaNs\n",
    "# print(X_train.isnull().sum()) \n",
    "# Check for Inf values \n",
    "# print(np.isinf(X_train).sum())  \n",
    "\n",
    "# X_error_correction_train = error_correction_train[features]\n",
    "# y_error_correction_train = error_correction_train[target]\n",
    "# X_val = error_correction_val[features]\n",
    "# y_val = error_correction_val[target]\n",
    "\n",
    "# X_error_correction_train = scaler.transform(X_error_correction_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val_single = scaler.transform(X_val_single)\n",
    "X_val_multi = scaler.transform(X_val_multi)\n",
    "\n",
    "X_test_single = scaler.transform(X_test_single)\n",
    "X_test_multi = scaler.transform(X_test_multi)\n",
    "\n",
    "# Add noise to the input features\n",
    "X_train = add_noise(X_train)\n",
    "X_val_single = add_noise(X_val_single)\n",
    "X_val_multi = add_noise(X_val_multi)\n",
    "X_test_single = add_noise(X_test_single)\n",
    "X_test_multi = add_noise(X_test_multi)\n",
    "\n",
    "# print(np.isnan(X_train).sum(), np.isinf(X_train).sum())\n",
    "\n",
    "# Define the model\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform exhaustive feature selection\n",
    "# efs = EFS(model, \n",
    "#           min_features=5,\n",
    "#           max_features=10,\n",
    "#           scoring='neg_mean_absolute_error',\n",
    "#           print_progress=True,\n",
    "#           cv=3,\n",
    "#           n_jobs=-1)\n",
    "\n",
    "# efs = efs.fit(X_train, y_train)\n",
    "\n",
    "# # Best features\n",
    "# best_features = list(efs.best_feature_names_)\n",
    "# print(f'Best features: {\"Selected Features by Exhaustive Feature Selection:\", best_features}')\n",
    "\n",
    "# # Train the model using selected features\n",
    "# X_train_selected = efs.transform(X_train)\n",
    "# X_val_selected = efs.transform(X_val)\n",
    "# X_test_selected = efs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to understand the trend\n",
    "data[target].plot(title='Actual NEL (GWh) Over Time', figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns in the DataFrame to numeric, forcing any non-numeric data to NaN\n",
    "train_data_numeric = train_data.apply(pd.to_numeric, errors='coerce')\n",
    "val_data_single_numeric = val_data_single.apply(pd.to_numeric, errors='coerce')\n",
    "val_data_multi_numeric = val_data_multi.apply(pd.to_numeric, errors='coerce')\n",
    "test_data_single_numeric = test_data_single.apply(pd.to_numeric, errors='coerce')\n",
    "test_data_multi_numeric = test_data_multi.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop or fill NaN values if any\n",
    "train_data_numeric = train_data_numeric.dropna()\n",
    "val_data_single_numeric = val_data_single_numeric.dropna()\n",
    "val_data_multi_numeric = val_data_multi_numeric.dropna()\n",
    "test_data_single_numeric = test_data_single_numeric.dropna()\n",
    "test_data_multi_numeric = test_data_multi_numeric.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameter grid for GridSearchCV for RandomForest model\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [50, 100, 150, 200],  # Number of trees in the forest\n",
    "#     'max_depth': [None, 10, 20, 30],      # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],      # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4],        # Minimum number of samples required to be at a leaf node\n",
    "#     'bootstrap': [True, False],           # Whether bootstrap samples are used when building trees\n",
    "#     'max_features': ['sqrt', 'log2'],     # The number of features to consider when looking for the best split\n",
    "#     'min_weight_fraction_leaf': [0.0, 0.01],  # Minimum weighted fraction of the input samples required to be at a leaf node\n",
    "# }\n",
    "\n",
    "# # Avoid using 'max_samples' when 'bootstrap=False'\n",
    "# if 'max_samples' in param_grid_rf:\n",
    "#     if False in param_grid_rf['bootstrap']:\n",
    "#         param_grid_rf['max_samples'] = [None, 0.5, 0.75]  # Use only when bootstrap=True\n",
    "\n",
    "# # Random Forest Grid Search\n",
    "# grid_search_rf = GridSearchCV(\n",
    "#     estimator=RandomForestRegressor(random_state=42),\n",
    "#     param_grid=param_grid_rf,\n",
    "#     cv=3,  # 3-fold cross-validation\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     verbose=2,\n",
    "#     error_score='raise'  # Set error_score to 'raise' to debug failing fits\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],     # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],               # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],               # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],                 # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]                     # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 150, 200, 250, 300],# Number of trees in the forest\n",
    "#     'max_depth': [None, 10, 20, 30],          # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],          # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4],            # Minimum number of samples required to be at a leaf node\n",
    "#     'bootstrap': [True, False],               # Whether bootstrap samples are used when building trees\n",
    "#     'max_features': ['sqrt', 'log2'],         # The number of features to consider when looking for the best split\n",
    "#     'min_weight_fraction_leaf': [0.0, 0.01],  # Minimum weighted fraction of the input samples required to be at a leaf node\n",
    "# }\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [150],\n",
    "#     'max_depth': [10],\n",
    "#     'min_samples_split': [2],\n",
    "#     'min_samples_leaf': [1],\n",
    "#     'bootstrap': [True]\n",
    "# }\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [250],\n",
    "#     'max_depth': [None],\n",
    "#     'min_samples_split': [2],\n",
    "#     'min_samples_leaf': [1],\n",
    "#     'bootstrap': [False]\n",
    "# }\n",
    "\n",
    "# Random Forest Grid Search\n",
    "# grid_search_rf = GridSearchCV(\n",
    "#     estimator=RandomForestRegressor(random_state=42),\n",
    "#     param_grid=param_grid_rf,\n",
    "#     cv=3,       # 3-fold cross-validation\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     verbose=2,\n",
    "# )\n",
    "\n",
    "# Avoid using 'max_samples' when 'bootstrap=False'\n",
    "if 'max_samples' in param_grid_rf:\n",
    "    if False in param_grid_rf['bootstrap']:\n",
    "        param_grid_rf['max_samples'] = [None, 0.5, 0.75]  # Use only when bootstrap=True\n",
    "\n",
    "# Random Forest Grid Search\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    # 3-fold cross-validation\n",
    "    cv=3,       \n",
    "    # Use all available cores\n",
    "    n_jobs=-1,  \n",
    "    verbose=2,\n",
    "    # Set error_score to 'raise' to debug failing fits\n",
    "    # error_score='raise' \n",
    ")\n",
    "\n",
    "# Perform grid search for randomforesting model\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters for randomforesting model\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f'Best parameters for randomforesting model: {best_params_rf}')\n",
    "\n",
    "# Train the best randomforesting model\n",
    "best_rf_model = RandomForestRegressor(**best_params_rf, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Randomforesting model evaluation on validation set\n",
    "y_val_randomforest_single = best_rf_model.predict(X_val_single)\n",
    "val_randomforest_mae_single = mean_absolute_error(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_mse_single = mean_squared_error(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_mape_single = mean_absolute_percentage_error(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_rmse_single = rmse(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_r2_single = r2_score(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_mbd_single = mean_bias_deviation(y_val_single, y_val_randomforest_single)\n",
    "val_randomforest_smape_single = smape(y_val_single, y_val_randomforest_single)\n",
    "\n",
    "print(f'Random Forest Single Year:')\n",
    "print(f'Validation MAE (Randomforest): {val_randomforest_mae_single}')\n",
    "print(f'Validation MSE (Randomforest): {val_randomforest_mse_single}')\n",
    "print(f'Validation MAPE (Randomforest): {val_randomforest_mape_single}')\n",
    "print(f'Validation RMSE (Randomforest): {val_randomforest_rmse_single}')\n",
    "print(f'Validation R² (Randomforest): {val_randomforest_r2_single}')\n",
    "print(f'Validation MBD (Randomforest): {val_randomforest_mbd_single}')\n",
    "print(f'Validation sMAPE (Randomforest): {val_randomforest_smape_single}')\n",
    "\n",
    "# Randomforesting model evaluation on validation set\n",
    "y_val_randomforest_multi = best_rf_model.predict(X_val_multi)\n",
    "val_randomforest_mae_multi = mean_absolute_error(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_mse_multi = mean_squared_error(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_mape_multi= mean_absolute_percentage_error(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_rmse_multi = rmse(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_r2_multi = r2_score(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_mbd_multi = mean_bias_deviation(y_val_multi, y_val_randomforest_multi)\n",
    "val_randomforest_smape_multi = smape(y_val_multi, y_val_randomforest_multi)\n",
    "\n",
    "print(f'Random Forest Multi Year:')\n",
    "print(f'Validation MAE (Randomforest): {val_randomforest_mae_multi}')\n",
    "print(f'Validation MSE (Randomforest): {val_randomforest_mse_multi}')\n",
    "print(f'Validation MAPE (Randomforest): {val_randomforest_mape_multi}')\n",
    "print(f'Validation RMSE (Randomforest): {val_randomforest_rmse_multi}')\n",
    "print(f'Validation R² (Randomforest): {val_randomforest_r2_multi}')\n",
    "print(f'Validation MBD (Randomforest): {val_randomforest_mbd_multi}')\n",
    "print(f'Validation sMAPE (Randomforest): {val_randomforest_smape_multi}')\n",
    "\n",
    "# Test the Randomforesting model(Single Year)\n",
    "y_test_randomforest_single = best_rf_model.predict(X_test_single)\n",
    "test_randomforest_mae_single = mean_absolute_error(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_mse_single = mean_squared_error(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_mape_single = mean_absolute_percentage_error(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_rmse_single = rmse(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_r2_single = r2_score(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_mbd_single = mean_bias_deviation(y_test_single, y_test_randomforest_single)\n",
    "test_randomforest_smape_single = smape(y_test_single, y_test_randomforest_single)\n",
    "\n",
    "print(f'Random Forest Single Year:')\n",
    "print(f'Test MAE (Randomforest): {test_randomforest_mae_single}')\n",
    "print(f'Test MSE (Randomforest): {test_randomforest_mse_single}')\n",
    "print(f'Test MAPE (Randomforest): {test_randomforest_mape_single}')\n",
    "print(f'Test RMSE (Randomforest): {test_randomforest_rmse_single}')\n",
    "print(f'Test R² (Randomforest): {test_randomforest_r2_single}')\n",
    "print(f'Test MBD (Randomforest): {test_randomforest_mbd_single}')\n",
    "print(f'Test sMAPE (Randomforest): {test_randomforest_smape_single}')\n",
    "\n",
    "y_test_randomforest_multi = best_rf_model.predict(X_test_multi)\n",
    "test_randomforest_mae_multi = mean_absolute_error(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_mse_multi = mean_squared_error(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_mape_multi = mean_absolute_percentage_error(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_rmse_multi = rmse(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_r2_multi = r2_score(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_mbd_multi = mean_bias_deviation(y_test_multi, y_test_randomforest_multi)\n",
    "test_randomforest_smape_multi = smape(y_test_multi, y_test_randomforest_multi)\n",
    "\n",
    "print(f'Random Forest Multi-Years:')\n",
    "print(f'Test MAE (Randomforest): {test_randomforest_mae_multi}')\n",
    "print(f'Test MSE (Randomforest): {test_randomforest_mse_multi}')\n",
    "print(f'Test MAPE (Randomforest): {test_randomforest_mape_multi}')\n",
    "print(f'Test RMSE (Randomforest): {test_randomforest_rmse_multi}')\n",
    "print(f'Test R² (Randomforest): {test_randomforest_r2_multi}')\n",
    "print(f'Test MBD (Randomforest): {test_randomforest_mbd_multi}')\n",
    "print(f'Test sMAPE (Randomforest): {test_randomforest_smape_multi}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameter grid for GridSearchCV for error correction model\n",
    "# param_grid_rfec = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [10, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV for error correction model\n",
    "# grid_search_rfec = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "#                               param_grid=param_grid_rfec,\n",
    "#                               cv=3,\n",
    "#                               n_jobs=-1,\n",
    "#                               verbose=2)\n",
    "\n",
    "# # Perform grid search for error correction model\n",
    "# grid_search_rfec.fit(X_error_correction_train, y_error_correction_train)\n",
    "\n",
    "# # Best hyperparameters for error correction model\n",
    "# best_params_rfec = grid_search_rfec.best_params_\n",
    "# print(f'Best parameters for error correction model: {best_params_rfec}')\n",
    "\n",
    "# # Train the best error correction model\n",
    "# best_rfec_model = RandomForestRegressor(**best_params_rfec, random_state=42)\n",
    "# best_rfec_model.fit(X_error_correction_train, y_error_correction_train)\n",
    "\n",
    "# # Error correction model evaluation on validation set\n",
    "# y_val_corrected = best_rfec_model.predict(X_val)\n",
    "# val_corrected_mae = mean_absolute_error(y_val, y_val_corrected)\n",
    "# val_corrected_mse = mean_squared_error(y_val, y_val_corrected)\n",
    "# val_corrected_mape = mean_absolute_percentage_error(y_val, y_val_corrected)\n",
    "# val_corrected_rmse = rmse(y_val, y_val_corrected)\n",
    "# val_corrected_r2 = r2_score(y_val, y_val_corrected)\n",
    "# val_corrected_mbd = mean_bias_deviation(y_val, y_val_corrected)\n",
    "# val_corrected_smape = smape(y_val, y_val_corrected)\n",
    "\n",
    "# print(f'Validation MAE (RF Error Correction): {val_corrected_mae}')\n",
    "# print(f'Validation MSE (RF Error Correction): {val_corrected_mse}')\n",
    "# print(f'Validation MAPE (RF Error Correction): {val_corrected_mape}')\n",
    "# print(f'Validation RMSE (RF Error Correction): {val_corrected_rmse}')\n",
    "# print(f'Validation R² (RF Error Correction): {val_corrected_r2}')\n",
    "# print(f'Validation MBD (RF Error Correction): {val_corrected_mbd}')\n",
    "# print(f'Validation sMAPE (RF Error Correction): {val_corrected_smape}')\n",
    "\n",
    "# # Test the error correction model\n",
    "# y_test_corrected = best_rfec_model.predict(X_test)\n",
    "# test_corrected_mae = mean_absolute_error(y_test, y_test_corrected)\n",
    "# test_corrected_mse = mean_squared_error(y_test, y_test_corrected)\n",
    "# test_corrected_mape = mean_absolute_percentage_error(y_test, y_test_corrected)\n",
    "# test_corrected_rmse = rmse(y_test, y_test_corrected)\n",
    "# test_corrected_r2 = r2_score(y_test, y_test_corrected)\n",
    "# test_corrected_mbd = mean_bias_deviation(y_test, y_test_corrected)\n",
    "# test_corrected_smape = smape(y_test, y_test_corrected)\n",
    "\n",
    "# print(f'Test MAE (RF Error Correction): {test_corrected_mae}')\n",
    "# print(f'Test MSE (RF Error Correction): {test_corrected_mse}')\n",
    "# print(f'Test MAPE (RF Error Correction): {test_corrected_mape}')\n",
    "# print(f'Test RMSE (RF Error Correction): {test_corrected_rmse}')\n",
    "# print(f'Test R² (RF Error Correction): {test_corrected_r2}')\n",
    "# print(f'Test MBD (RF Error Correction): {test_corrected_mbd}')\n",
    "# print(f'Test sMAPE (RF Error Correction): {test_corrected_smape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (Randomforesting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values, label='Actual Values')\n",
    "plt.plot(y_val_randomforest_single, label='Randomforested Values')\n",
    "plt.title('Random Foresting Model: Actual vs Randomforested Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMavpVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the validation set (Randomforesting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values, label='Actual Values')\n",
    "plt.plot(y_val_randomforest_multi, label='Randomforested Values')\n",
    "plt.title('Random Foresting Model: Actual vs Randomforested Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMavpVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (Randomforesting Model)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values, label='Actual Values')\n",
    "plt.plot(y_test_randomforest_single, label='Randomforested Values')\n",
    "plt.title('Random Foresting Model: Actual vs Randomforested Values (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMavpTS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (Randomforesting Model)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values, label='Actual Values')\n",
    "plt.plot(y_test_randomforest_multi, label='Randomforested Values')\n",
    "plt.title('Random Foresting Model: Actual vs Randomforested Values (Test Set - Multi)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMavpTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (Randomforesting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values - y_val_randomforest_single, label='Residuals')\n",
    "plt.title('Random Foresting Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMrVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (Randomforesting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values - y_val_randomforest_multi, label='Residuals')\n",
    "plt.title('Random Foresting Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMrVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the test set (Randomforesting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values - y_test_randomforest_single, label='Residuals')\n",
    "plt.title('Random Foresting Model: Residuals (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMrTS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the test set (Randomforesting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values - y_test_randomforest_multi, label='Residuals')\n",
    "plt.title('Random Foresting Model: Residuals (Test Set - Multi)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'RFMrTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Validation Set - True vs Predicted Values (Random Forest):\")\n",
    "# for true_val, pred_val in zip(y_val.values, y_val_forecast):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")\n",
    "\n",
    "# # Print true vs predicted values for the test set(Single)\n",
    "# print(\"\\nTest Set - True vs Predicted Values (Random Forest - Single):\")\n",
    "# for true_val, pred_val in zip(y_test_single.values, y_test_forecast):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")\n",
    "\n",
    "# # Print true vs predicted values for the test set(Multi)\n",
    "# print(\"\\nTest Set - True vs Predicted Values (Random Forest - Multi):\")\n",
    "# for true_val, pred_val in zip(y_test_multi.values, y_test_forecast):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get feature importances\n",
    "# feature_importances = best_rf_model.feature_importances_\n",
    "# # features_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "# features_importance_df = pd.DataFrame({'Feature': best_features, 'Importance': feature_importances})\n",
    "# features_importance_df = features_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Plot feature importances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='Importance', y='Feature', data=features_importance_df)\n",
    "# plt.title('Feature Importances')\n",
    "# plt.show()\n",
    "\n",
    "# # Display feature importances\n",
    "# print(features_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (RF Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_val.values, label='Actual Values')\n",
    "# plt.plot(y_val_corrected, label='Corrected Values')\n",
    "# plt.title('RF Error Correction Model: Actual vs Corrected Values (Validation Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Actual NEL (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'RFECMavpVS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (RF Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_test.values, label='Actual Values')\n",
    "# plt.plot(y_test_corrected, label='Corrected Values')\n",
    "# plt.title('RF Error Correction Model: Actual vs Corrected Values (Test Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Actual NEL (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'RFECMavpTS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (RF Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_val.values - y_val_corrected, label='Residuals')\n",
    "# plt.title('RF Error Correction Model: Residuals (Validation Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Residual (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'RFECMrVS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot residuals for the test set (RF Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_test.values - y_test_corrected, label='Residuals')\n",
    "# plt.title('RF Error Correction Model: Residuals (Test Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Residual (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'RFECMrTS.png'))\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Define parameter grid for GridSearchCV for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define parameter grid for GridSearchCV for Gradient Boosting\n",
    "# param_grid_gb = {\n",
    "#     'n_estimators': [100, 200, 300, 400],          # Number of boosting stages to be run\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.2],       # Learning rate shrinks the contribution of each tree\n",
    "#     'max_depth': [3, 5, 7, 10],                    # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],               # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4],                 # Minimum number of samples required to be at a leaf node\n",
    "#     'subsample': [0.8, 1.0],                       # Fraction of samples used for fitting the individual base learners\n",
    "#     'max_features': ['sqrt', 'log2', None],        # Number of features to consider when looking for the best split\n",
    "#     'loss': ['ls', 'lad', 'huber'],\n",
    "#     'alpha': [0.9, 0.95, 0.99]\n",
    "# }\n",
    "\n",
    "# param_grid_gb = {\n",
    "#     'n_estimators': [300],\n",
    "#     'learning_rate': [0.1],\n",
    "#     'max_depth': [3],\n",
    "#     'min_samples_split': [10],\n",
    "#     'min_samples_leaf': [1]\n",
    "# }\n",
    "\n",
    "# Gradient Boosting Grid Search\n",
    "grid_search_gb = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42),\n",
    "    param_grid=param_grid_gb,\n",
    "    cv=3,       # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform grid search for Gradient Boosting model\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters for Gradient Boosting model\n",
    "best_params_gb = grid_search_gb.best_params_\n",
    "print(f'Best parameters for Gradient Boosting model: {best_params_gb}')\n",
    "\n",
    "# Train the best Gradient Boosting model\n",
    "best_gradientboosting_model = GradientBoostingRegressor(**best_params_gb, random_state=42)\n",
    "best_gradientboosting_model.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting model evaluation on validation set(Single Year)\n",
    "y_val_gradientboost_single = best_gradientboosting_model.predict(X_val_single)\n",
    "val_gradientboost_mae_single = mean_absolute_error(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_mse_single = mean_squared_error(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_mape_single = mean_absolute_percentage_error(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_rmse_single = rmse(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_r2_single = r2_score(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_mbd_single= mean_bias_deviation(y_val_single, y_val_gradientboost_single)\n",
    "val_gradientboost_smape_single = smape(y_val_single, y_val_gradientboost_single)\n",
    "\n",
    "print(f'Gradient Boost Single Year:')\n",
    "print(f'Validation MAE (Gradient Boosting): {val_gradientboost_mae_single}')\n",
    "print(f'Validation MSE (Gradient Boosting): {val_gradientboost_mse_single}')\n",
    "print(f'Validation MAPE (Gradient Boosting): {val_gradientboost_mape_single}')\n",
    "print(f'Validation RMSE (Gradient Boosting): {val_gradientboost_rmse_single}')\n",
    "print(f'Validation R² (Gradient Boosting): {val_gradientboost_r2_single}')\n",
    "print(f'Validation MBD (Gradient Boosting): {val_gradientboost_mbd_single}')\n",
    "print(f'Validation sMAPE (Gradient Boosting): {val_gradientboost_smape_single}')\n",
    "\n",
    "# Gradient Boosting model evaluation on validation set(Multi Year)\n",
    "y_val_gradientboost_multi = best_gradientboosting_model.predict(X_val_multi)\n",
    "val_gradientboost_mae_multi = mean_absolute_error(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_mse_multi = mean_squared_error(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_mape_multi = mean_absolute_percentage_error(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_rmse_multi = rmse(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_r2_multi = r2_score(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_mbd_multi = mean_bias_deviation(y_val_multi, y_val_gradientboost_multi)\n",
    "val_gradientboost_smape_multi = smape(y_val_multi, y_val_gradientboost_multi)\n",
    "\n",
    "print(f'Gradient Boost Multi-Year:')\n",
    "print(f'Validation MAE (Gradient Boosting): {val_gradientboost_mae_multi}')\n",
    "print(f'Validation MSE (Gradient Boosting): {val_gradientboost_mse_multi}')\n",
    "print(f'Validation MAPE (Gradient Boosting): {val_gradientboost_mape_multi}')\n",
    "print(f'Validation RMSE (Gradient Boosting): {val_gradientboost_rmse_multi}')\n",
    "print(f'Validation R² (Gradient Boosting): {val_gradientboost_r2_multi}')\n",
    "print(f'Validation MBD (Gradient Boosting): {val_gradientboost_mbd_multi}')\n",
    "print(f'Validation sMAPE (Gradient Boosting): {val_gradientboost_smape_multi}')\n",
    "\n",
    "# Test the Gradient Boosting model(Single Year)\n",
    "y_test_gradientboost_single = best_gradientboosting_model.predict(X_test_single)\n",
    "test_gradientboost_mae_single = mean_absolute_error(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_mse_single = mean_squared_error(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_mape_single = mean_absolute_percentage_error(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_rmse_single = rmse(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_r2_single = r2_score(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_mbd_single = mean_bias_deviation(y_test_single, y_test_gradientboost_single)\n",
    "test_gradientboost_smape_single = smape(y_test_single, y_test_gradientboost_single)\n",
    "\n",
    "print(f'Gradient Boost Single Year:')\n",
    "print(f'Test MAE (Gradient Boosting): {test_gradientboost_mae_single}')\n",
    "print(f'Test MSE (Gradient Boosting): {test_gradientboost_mse_single}')\n",
    "print(f'Test MAPE (Gradient Boosting): {test_gradientboost_mape_single}')\n",
    "print(f'Test RMSE (Gradient Boosting): {test_gradientboost_rmse_single}')\n",
    "print(f'Test R² (Gradient Boosting): {test_gradientboost_r2_single}')\n",
    "print(f'Test MBD (Gradient Boosting): {test_gradientboost_mbd_single}')\n",
    "print(f'Test sMAPE (Gradient Boosting): {test_gradientboost_smape_single}')\n",
    "\n",
    "# Test the Gradient Boosting model(Multi Year)\n",
    "y_test_gradientboost_multi = best_gradientboosting_model.predict(X_test_multi)\n",
    "test_gradientboost_mae_multi = mean_absolute_error(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_mse_multi = mean_squared_error(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_mape_multi = mean_absolute_percentage_error(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_rmse_multi = rmse(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_r2_multi = r2_score(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_mbd_multi = mean_bias_deviation(y_test_multi, y_test_gradientboost_multi)\n",
    "test_gradientboost_smape_multi = smape(y_test_multi, y_test_gradientboost_multi)\n",
    "\n",
    "print(f'Gradient Boost Multi-Year:')\n",
    "print(f'Test MAE (Gradient Boosting): {test_gradientboost_mae_multi}')\n",
    "print(f'Test MSE (Gradient Boosting): {test_gradientboost_mse_multi}')\n",
    "print(f'Test MAPE (Gradient Boosting): {test_gradientboost_mape_multi}')\n",
    "print(f'Test RMSE (Gradient Boosting): {test_gradientboost_rmse_multi}')\n",
    "print(f'Test R² (Gradient Boosting): {test_gradientboost_r2_multi}')\n",
    "print(f'Test MBD (Gradient Boosting): {test_gradientboost_mbd_multi}')\n",
    "print(f'Test sMAPE (Gradient Boosting): {test_gradientboost_smape_multi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameter grid for GridSearchCV for Gradient Boosting\n",
    "# param_grid_gbec = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV for Gradient Boosting model\n",
    "# grid_search_gbec = GridSearchCV(estimator=GradientBoostingRegressor(random_state=42),\n",
    "#                               param_grid=param_grid_gbec,\n",
    "#                               cv=3,\n",
    "#                               n_jobs=-1,\n",
    "#                               verbose=2)\n",
    "\n",
    "# # Perform grid search for Gradient Boosting model\n",
    "# grid_search_gbec.fit(X_error_correction_train, y_error_correction_train)\n",
    "\n",
    "# # Best hyperparameters for Gradient Boosting model\n",
    "# best_params_gbec = grid_search_gbec.best_params_\n",
    "# print(f'Best parameters for Gradient Boosting model: {best_params_gbec}')\n",
    "\n",
    "# # Train the best Gradient Boosting model\n",
    "# best_gbec_model = GradientBoostingRegressor(**best_params_gbec, random_state=42)\n",
    "# best_gbec_model.fit(X_error_correction_train, y_error_correction_train)\n",
    "\n",
    "# # Gradient Boosting model evaluation on validation set\n",
    "# y_val_corrected_gb = best_gbec_model.predict(X_val)\n",
    "# val_corrected_gb_mae = mean_absolute_error(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_mse = mean_squared_error(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_mape = mean_absolute_percentage_error(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_rmse = rmse(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_r2 = r2_score(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_mbd = mean_bias_deviation(y_val, y_val_corrected_gb)\n",
    "# val_corrected_gb_smape = smape(y_val, y_val_corrected_gb)\n",
    "\n",
    "# print(f'Validation MAE (GB Error Correction): {val_corrected_gb_mae}')\n",
    "# print(f'Validation MSE (GB Error Correction): {val_corrected_gb_mse}')\n",
    "# print(f'Validation MAPE (GB Error Correction): {val_corrected_gb_mape}')\n",
    "# print(f'Validation RMSE (GB Error Correction): {val_corrected_gb_rmse}')\n",
    "# print(f'Validation R² (GB Error Correction): {val_corrected_gb_r2}')\n",
    "# print(f'Validation MBD (GB Error Correction): {val_corrected_gb_mbd}')\n",
    "# print(f'Validation sMAPE (GB Error Correction): {val_corrected_gb_smape}')\n",
    "\n",
    "# # Test the Gradient Boosting model\n",
    "# y_test_corrected_gb = best_gbec_model.predict(X_test)\n",
    "# test_corrected_gb_mae = mean_absolute_error(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_mse = mean_squared_error(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_mape = mean_absolute_percentage_error(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_rmse = rmse(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_r2 = r2_score(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_mbd = mean_bias_deviation(y_test, y_test_corrected_gb)\n",
    "# test_corrected_gb_smape = smape(y_test, y_test_corrected_gb)\n",
    "\n",
    "# print(f'Test MAE (GB Error Correction): {test_corrected_gb_mae}')\n",
    "# print(f'Test MSE (GB Error Correction): {test_corrected_gb_mse}')\n",
    "# print(f'Test MAPE (GB Error Correction): {test_corrected_gb_mape}')\n",
    "# print(f'Test RMSE (GB Error Correction): {test_corrected_gb_rmse}')\n",
    "# print(f'Test R² (GB Error Correction): {test_corrected_gb_r2}')\n",
    "# print(f'Test MBD (GB Error Correction): {test_corrected_gb_mbd}')\n",
    "# print(f'Test sMAPE (GB Error Correction): {test_corrected_gb_smape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (Gradientboosting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values, label='Actual Values')\n",
    "plt.plot(y_val_gradientboost_single, label='Gradientboosted Values')\n",
    "plt.title('Gradient Boosting Model: Actual vs Gradientboosted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMavpVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the validation set (Gradientboosting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values, label='Actual Values')\n",
    "plt.plot(y_val_gradientboost_multi, label='Gradientboosted Values')\n",
    "plt.title('Gradient Boosting Model: Actual vs Gradientboosted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMavpVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (Gradientboosting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values, label='Actual Values')\n",
    "plt.plot(y_test_gradientboost_single, label='Gradientboosted Values')\n",
    "plt.title('Gradient Boosting Model: Actual vs Gradientboosted Values (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMavpTS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (Gradientboosting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values, label='Actual Values')\n",
    "plt.plot(y_test_gradientboost_multi, label='Gradientboosted Values')\n",
    "plt.title('Gradient Boosting Model: Actual vs Gradientboosted Values (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMavpTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (Gradientboosting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values - y_val_gradientboost_single, label='Residuals')\n",
    "plt.title('Gradient Boosting Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMrVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (Gradientboosting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values - y_val_gradientboost_multi, label='Residuals')\n",
    "plt.title('Gradient Boosting Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMrVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the test set (Gradientboosting Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values - y_test_gradientboost_single, label='Residuals')\n",
    "plt.title('Gradient Boosting Model: Residuals (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMrTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the test set (Gradientboosting Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values - y_test_gradientboost_multi, label='Residuals')\n",
    "plt.title('Gradient Boosting Model: Residuals (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'GBMrTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nValidation Set - True vs Predicted Values (Gradient Boosting):\")\n",
    "# for true_val, pred_val in zip(y_val.values, y_val_gradientboost):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")\n",
    "\n",
    "# print(\"\\nTest Set - True vs Predicted Values (Gradient Boosting - Single):\")\n",
    "# for true_val, pred_val in zip(y_test_single.values, y_test_gradientboost):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")\n",
    "\n",
    "# print(\"\\nTest Set - True vs Predicted Values (Gradient Boosting - Multi):\")\n",
    "# for true_val, pred_val in zip(y_test_multi.values, y_test_gradientboost):\n",
    "#     print(f\"True: {true_val}, Predicted: {pred_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (GB Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_val.values, label='Actual Values')\n",
    "# plt.plot(y_val_corrected_gb, label='Corrected Values (GBM)')\n",
    "# plt.title('GB Error Correction Model: Actual vs Corrected Values (Validation Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Actual NEL (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'GBECMavpVS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (GB Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_test.values, label='Actual Values')\n",
    "# plt.plot(y_test_corrected_gb, label='Corrected Values (GBM)')\n",
    "# plt.title('GB Error Correction Model: Actual vs Corrected Values (Test Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Actual NEL (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'GBECMavpTS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (GB Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_val.values - y_val_corrected_gb, label='Residuals (GBM)')\n",
    "# plt.title('GB Error Correction Model: Residuals (Validation Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Residual (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'GBECMrVS.png'))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Plot residuals for the test set (GB Error Correction Model)\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(y_test.values - y_test_corrected_gb, label='Residuals (GBM)')\n",
    "# plt.title('GB Error Correction Model: Residuals (Test Set)')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Residual (GWh)')\n",
    "# plt.legend()\n",
    "# plt.savefig(os.path.join(output_dir, 'GBECMrTS.png'))\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Ensure the data is sorted by Year and Month\n",
    "train_data_numeric = train_data_numeric.sort_values(['Year', 'Month'])\n",
    "\n",
    "val_data_single_numeric = val_data_single_numeric.sort_values(['Year', 'Month'])\n",
    "val_data_multi_numeric = val_data_multi_numeric.sort_values(['Year', 'Month'])\n",
    "\n",
    "test_data_single_numeric = test_data_single_numeric.sort_values(['Year', 'Month'])\n",
    "test_data_multi_numeric = test_data_multi_numeric.sort_values(['Year', 'Month'])\n",
    "\n",
    "# Set a proper datetime index(Single & Multi)\n",
    "train_data_numeric['Date'] = pd.to_datetime(train_data_numeric[['Year', 'Month']].assign(DAY=1))\n",
    "train_data_numeric.set_index('Date', inplace=True)\n",
    "\n",
    "val_data_single_numeric['Date'] = pd.to_datetime(val_data_single_numeric[['Year', 'Month']].assign(DAY=1))\n",
    "val_data_single_numeric.set_index('Date', inplace=True)\n",
    "\n",
    "val_data_multi_numeric['Date'] = pd.to_datetime(val_data_multi_numeric[['Year', 'Month']].assign(DAY=1))\n",
    "val_data_multi_numeric.set_index('Date', inplace=True)\n",
    "\n",
    "test_data_single_numeric['Date'] = pd.to_datetime(test_data_single_numeric[['Year', 'Month']].assign(DAY=1))\n",
    "test_data_single_numeric.set_index('Date', inplace=True)\n",
    "\n",
    "test_data_multi_numeric['Date'] = pd.to_datetime(test_data_multi_numeric[['Year', 'Month']].assign(DAY=1))\n",
    "test_data_multi_numeric.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'MS' stands for month start\n",
    "train_data_numeric = train_data_numeric.asfreq('MS')  \n",
    "val_data_single_numeric = val_data_single_numeric.asfreq('MS')\n",
    "val_data_multi_numeric = val_data_multi_numeric.asfreq('MS')\n",
    "\n",
    "test_data_single_numeric = test_data_single_numeric.asfreq('MS')\n",
    "test_data_multi_numeric = test_data_multi_numeric.asfreq('MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure y_true and y_pred are numeric\n",
    "def mean_bias_deviation(y_true, y_pred):\n",
    "    y_true = pd.to_numeric(y_true, errors='coerce')\n",
    "    y_pred = pd.to_numeric(y_pred, errors='coerce')\n",
    "    return np.mean(y_true - y_pred)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = pd.to_numeric(y_true, errors='coerce')\n",
    "    y_pred = pd.to_numeric(y_pred, errors='coerce')\n",
    "    return np.mean(np.abs(y_true - y_pred) / ((np.abs(y_true) + np.abs(y_pred)) / 2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "model_arima = ARIMA(train_data_numeric[target], order=(5, 1, 0), freq='MS')\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# randomforest on validation and test sets(Single & Multi)\n",
    "y_val_arima_single = model_arima_fit.forecast(steps=len(y_val_single))\n",
    "y_val_arima_multi = model_arima_fit.forecast(steps=len(y_val_multi))\n",
    "# y_val_arima_single = model_arima_fit.forecast(steps=len(val_data_single_numeric))\n",
    "# y_val_arima_multi = model_arima_fit.forecast(steps=len(val_data_multi_numeric))\n",
    "\n",
    "y_test_arima_single = model_arima_fit.forecast(steps=len(test_data_single))\n",
    "y_test_arima_multi = model_arima_fit.forecast(steps=len(test_data_multi))\n",
    "\n",
    "# Validation metrics for ARIMA model(Single Year)\n",
    "val_arima_mae_single = mean_absolute_error(y_val_single, y_val_arima_single)\n",
    "val_arima_mse_single = mean_squared_error(y_val_single, y_val_arima_single)\n",
    "val_arima_mape_single = mean_absolute_percentage_error(y_val_single, y_val_arima_single)\n",
    "val_arima_rmse_single = rmse(y_val_single, y_val_arima_single)\n",
    "val_arima_r2_single = r2_score(y_val_single, y_val_arima_single)\n",
    "val_arima_mbd_single = mean_bias_deviation(y_val_single, y_val_arima_single)\n",
    "val_arima_smape_single = smape(y_val_single, y_val_arima_single)\n",
    "\n",
    "print(f'ARIMA Single Year:')\n",
    "print(f'Validation MAE (ARIMA): {val_arima_mae_single}')\n",
    "print(f'Validation MSE (ARIMA): {val_arima_mse_single}')\n",
    "print(f'Validation MAPE (ARIMA): {val_arima_mape_single}')\n",
    "print(f'Validation RMSE (ARIMA): {val_arima_rmse_single}')\n",
    "print(f'Validation R² (ARIMA): {val_arima_r2_single}')\n",
    "print(f'Validation MBD (ARIMA): {val_arima_mbd_single}')\n",
    "print(f'Validation sMAPE (ARIMA): {val_arima_smape_single}')\n",
    "\n",
    "# Validation metrics for ARIMA model(Multi Year)\n",
    "val_arima_mae_multi = mean_absolute_error(y_val_multi, y_val_arima_multi)\n",
    "val_arima_mse_multi = mean_squared_error(y_val_multi, y_val_arima_multi)\n",
    "val_arima_mape_multi = mean_absolute_percentage_error(y_val_multi, y_val_arima_multi)\n",
    "val_arima_rmse_multi = rmse(y_val_multi, y_val_arima_multi)\n",
    "val_arima_r2_multi = r2_score(y_val_multi, y_val_arima_multi)\n",
    "val_arima_mbd_multi = mean_bias_deviation(y_val_multi, y_val_arima_multi)\n",
    "val_arima_smape_multi = smape(y_val_multi, y_val_arima_multi)\n",
    "\n",
    "print(f'ARIMA Multi Year:')\n",
    "print(f'Validation MAE (ARIMA): {val_arima_mae_multi}')\n",
    "print(f'Validation MSE (ARIMA): {val_arima_mse_multi}')\n",
    "print(f'Validation MAPE (ARIMA): {val_arima_mape_multi}')\n",
    "print(f'Validation RMSE (ARIMA): {val_arima_rmse_multi}')\n",
    "print(f'Validation R² (ARIMA): {val_arima_r2_multi}')\n",
    "print(f'Validation MBD (ARIMA): {val_arima_mbd_multi}')\n",
    "print(f'Validation sMAPE (ARIMA): {val_arima_smape_multi}')\n",
    "\n",
    "# Test metrics for ARIMA model (Single Year)\n",
    "test_arima_mae_single = mean_absolute_error(y_test_single, y_test_arima_single)\n",
    "test_arima_mse_single = mean_squared_error(y_test_single, y_test_arima_single)\n",
    "test_arima_mape_single = mean_absolute_percentage_error(y_test_single, y_test_arima_single)\n",
    "test_arima_rmse_single = rmse(y_test_single, y_test_arima_single)\n",
    "test_arima_r2_single = r2_score(y_test_single, y_test_arima_single)\n",
    "test_arima_mbd_single = mean_bias_deviation(y_test_single, y_test_arima_single)\n",
    "test_arima_smape_single = smape(y_test_single, y_test_arima_single)\n",
    "\n",
    "print(f'ARIMA Single Year:')\n",
    "print(f'Test MAE (ARIMA): {test_arima_mae_single}')\n",
    "print(f'Test MSE (ARIMA): {test_arima_mse_single}')\n",
    "print(f'Test MAPE (ARIMA): {test_arima_mape_single}')\n",
    "print(f'Test RMSE (ARIMA): {test_arima_rmse_single}')\n",
    "print(f'Test R² (ARIMA): {test_arima_r2_single}')\n",
    "print(f'Test MBD (ARIMA): {test_arima_mbd_single}')\n",
    "print(f'Test sMAPE (ARIMA): {test_arima_smape_single}')\n",
    "\n",
    "# Test metrics for ARIMA model (Multi-Year)\n",
    "test_arima_mae_multi = mean_absolute_error(y_test_multi, y_test_arima_multi)\n",
    "test_arima_mse_multi = mean_squared_error(y_test_multi, y_test_arima_multi)\n",
    "test_arima_mape_multi = mean_absolute_percentage_error(y_test_multi, y_test_arima_multi)\n",
    "test_arima_rmse_multi = rmse(y_test_multi, y_test_arima_multi)\n",
    "test_arima_r2_multi = r2_score(y_test_multi, y_test_arima_multi)\n",
    "test_arima_mbd_multi = mean_bias_deviation(y_test_multi, y_test_arima_multi)\n",
    "test_arima_smape_multi = smape(y_test_multi, y_test_arima_multi)\n",
    "\n",
    "print(f'ARIMA Multi Year:')\n",
    "print(f'Test MAE (ARIMA): {test_arima_mae_multi}')\n",
    "print(f'Test MSE (ARIMA): {test_arima_mse_multi}')\n",
    "print(f'Test MAPE (ARIMA): {test_arima_mape_multi}')\n",
    "print(f'Test RMSE (ARIMA): {test_arima_rmse_multi}')\n",
    "print(f'Test R² (ARIMA): {test_arima_r2_multi}')\n",
    "print(f'Test MBD (ARIMA): {test_arima_mbd_multi}')\n",
    "print(f'Test sMAPE (ARIMA): {test_arima_smape_multi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (ARIMA Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values, label='Actual Values')\n",
    "plt.plot(y_val_arima_single.values, label='ARIMA Predicted Values', linestyle='--')\n",
    "plt.title('ARIMA Model: Actual vs Predicted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMAavpVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the validation set (ARIMA Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values, label='Actual Values')\n",
    "plt.plot(y_val_arima_multi.values, label='ARIMA Predicted Values', linestyle='--')\n",
    "plt.title('ARIMA Model: Actual vs Predicted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMAavpVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the single year test set (ARIMA Model)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values, label='Actual Values')\n",
    "plt.plot(y_test_arima_single.values, label='ARIMA Predicted Values', linestyle='--')\n",
    "plt.title('ARIMA Model: Actual vs Predicted Values (Test Set - Multi-Year)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMAavpTS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the multi-year test set (ARIMA Model)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values, label='Actual Values')\n",
    "plt.plot(y_test_arima_multi.values, label='ARIMA Predicted Values', linestyle='--')\n",
    "plt.title('ARIMA Model: Actual vs Predicted Values (Test Set - Multi-Year)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMAavpTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (ARIMA Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values - y_val_arima_single.values, label='Residuals')\n",
    "plt.title('ARIMA Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMArVS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the validation set (ARIMA Model- Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values - y_val_arima_multi.values, label='Residuals')\n",
    "plt.title('ARIMA Model: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMArVS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the multi-year test set (ARIMA Model - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values - y_test_arima_single.values, label='Residuals')\n",
    "plt.title('ARIMA Model: Residuals (Test Set - Multi-Year)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMArTS_S.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for the multi-year test set (ARIMA Model - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values - y_test_arima_multi.values, label='Residuals')\n",
    "plt.title('ARIMA Model: Residuals (Test Set - Multi-Year)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'ARIMArTS_M.png'))\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for the validation set (All Models - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values, label='Actual Values')\n",
    "plt.plot(y_val_randomforest_single, label='Random Forest Predicted Values')\n",
    "plt.plot(y_val_gradientboost_single, label='Gradient Boosting Predicted Values', linestyle='--')\n",
    "plt.plot(y_val_arima_single.values, label='ARIMA Predicted Values', linestyle='-.')\n",
    "plt.title('All Models: Actual vs Predicted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NFor plot(y_val_gradientboost_multi, label='Gradient Boosting Predicted Values', linestyle='--')\n",
    "plt.plot(y_val_arima_multi.values, label='ARIMA Predicted Values', linestyle='-.')\n",
    "plt.title('All Models: Actual vs Predicted Values (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelavpVS_S.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (All Models - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values, label='Actual Values')\n",
    "plt.plot(y_test_randomforest_single, label='Random Forest Predicted Values')\n",
    "plt.plot(y_test_gradientboost_single, label='Gradient Boosting Predicted Values', linestyle='--')\n",
    "plt.plot(y_test_arima_single.values, label='ARIMA Predicted Values', linestyle='-.')\n",
    "plt.title('All Models: Actual vs Predicted Values (Test Set - Multi)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelavpTS_S.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot actual vs. predicted values for the test set (All Models - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values, label='Actual Values')\n",
    "plt.plot(y_test_randomforest_multi, label='Random Forest Predicted Values')\n",
    "plt.plot(y_test_gradientboost_multi, label='Gradient Boosting Predicted Values', linestyle='--')\n",
    "plt.plot(y_test_arima_multi.values, label='ARIMA Predicted Values', linestyle='-.')\n",
    "plt.title('All Models: Actual vs Predicted Values (Test Set - Multi)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Actual NEL (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelavpTS_M.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals vs actual values for the validation set (All Models - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_single.values - y_val_randomforest_single, label='Random Forest Residuals')\n",
    "plt.plot(y_val_single.values - y_val_gradientboost_single, label='Gradient Boosting Residuals')\n",
    "plt.plot(y_val_single.values - y_val_arima_single.values, label='ARIMA Residuals', linestyle='-.')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('All Models: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelrvaVS_S.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals vs actual values for the validation set (All Models - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_val_multi.values - y_val_randomforest_multi, label='Random Forest Residuals')\n",
    "plt.plot(y_val_multi.values - y_val_gradientboost_multi, label='Gradient Boosting Residuals')\n",
    "plt.plot(y_val_multi.values - y_val_arima_multi.values, label='ARIMA Residuals', linestyle='-.')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('All Models: Residuals (Validation Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelrvaVS_M.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals vs actual values for the test set (All Models - Single)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_single.values - y_test_randomforest_single, label='Random Forest Residuals')\n",
    "plt.plot(y_test_single.values - y_test_gradientboost_single, label='Gradient Boosting Residuals')\n",
    "plt.plot(y_test_single.values - y_test_arima_single.values, label='ARIMA Residuals', linestyle='-.')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('All Models: Residuals (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelrvaTS_S.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals vs actual values for the test set (All Models - Multi)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_multi.values - y_test_randomforest_multi, label='Random Forest Residuals')\n",
    "plt.plot(y_test_multi.values - y_test_gradientboost_multi, label='Gradient Boosting Residuals')\n",
    "plt.plot(y_test_multi.values - y_test_arima_multi.values, label='ARIMA Residuals', linestyle='-.')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('All Models: Residuals (Test Set)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Residual (GWh)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/allModelrvaTS_M.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Random Forest Forecasting Model - Single\n",
    "rf_forecast_metrics_single = {\n",
    "    'Model': 'Random Forest',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_randomforest_mae_single,\n",
    "    'Validation MSE': val_randomforest_mse_single,\n",
    "    'Validation MAPE': val_randomforest_mape_single,\n",
    "    'Validation RMSE': val_randomforest_rmse_single,\n",
    "    'Validation R²': val_randomforest_r2_single,\n",
    "    'Validation MBD': val_randomforest_mbd_single,\n",
    "    'Validation sMAPE': val_randomforest_smape_single,\n",
    "    'Test MAE': test_randomforest_mae_single,\n",
    "    'Test MSE': test_randomforest_mse_single,\n",
    "    'Test MAPE': test_randomforest_mape_single,\n",
    "    'Test RMSE': test_randomforest_rmse_single,\n",
    "    'Test R²': test_randomforest_r2_single,\n",
    "    'Test MBD': test_randomforest_mbd_single,\n",
    "    'Test sMAPE': test_randomforest_smape_single\n",
    "}\n",
    "\n",
    "# Metrics for Random Forest Forecasting Model - Multi\n",
    "rf_forecast_metrics_multi = {\n",
    "    'Model': 'Random Forest',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_randomforest_mae_multi,\n",
    "    'Validation MSE': val_randomforest_mse_multi,\n",
    "    'Validation MAPE': val_randomforest_mape_multi,\n",
    "    'Validation RMSE': val_randomforest_rmse_multi,\n",
    "    'Validation R²': val_randomforest_r2_multi,\n",
    "    'Validation MBD': val_randomforest_mbd_multi,\n",
    "    'Validation sMAPE': val_randomforest_smape_multi,\n",
    "    'Test MAE': test_randomforest_mae_multi,\n",
    "    'Test MSE': test_randomforest_mse_multi,\n",
    "    'Test MAPE': test_randomforest_mape_multi,\n",
    "    'Test RMSE': test_randomforest_rmse_multi,\n",
    "    'Test R²': test_randomforest_r2_multi,\n",
    "    'Test MBD': test_randomforest_mbd_multi,\n",
    "    'Test sMAPE': test_randomforest_smape_multi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Random Forest Error Correction Model\n",
    "# rf_error_correction_metrics = {\n",
    "#     'Model': 'Random Forest',\n",
    "#     'Task': 'Error Correction',\n",
    "#     'Validation MAE': val_corrected_mae,\n",
    "#     'Validation MSE': val_corrected_mse,\n",
    "#     'Validation MAPE': val_corrected_mape,\n",
    "#     'Validation RMSE': val_corrected_rmse,\n",
    "#     'Validation R²': val_corrected_r2,\n",
    "#     'Validation MBD': val_corrected_mbd,\n",
    "#     'Validation sMAPE': val_corrected_smape,\n",
    "#     'Test MAE': test_corrected_mae,\n",
    "#     'Test MSE': test_corrected_mse,\n",
    "#     'Test MAPE': test_corrected_mape,\n",
    "#     'Test RMSE': test_corrected_rmse,\n",
    "#     'Test R²': test_corrected_r2,\n",
    "#     'Test MBD': test_corrected_mbd,\n",
    "#     'Test sMAPE': test_corrected_smape\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Gradient Boosting Forecasting Model - Single\n",
    "gb_forecast_metrics_single = {\n",
    "    'Model': 'Gradient Boosting',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_gradientboost_mae_single,\n",
    "    'Validation MSE': val_gradientboost_mse_single,\n",
    "    'Validation MAPE': val_gradientboost_mape_single,\n",
    "    'Validation RMSE': val_gradientboost_rmse_single,\n",
    "    'Validation R²': val_gradientboost_r2_single,\n",
    "    'Validation MBD': val_gradientboost_mbd_single,\n",
    "    'Validation sMAPE': val_gradientboost_smape_single,\n",
    "    'Test MAE': test_gradientboost_mae_single,\n",
    "    'Test MSE': test_gradientboost_mse_single,\n",
    "    'Test MAPE': test_gradientboost_mape_single,\n",
    "    'Test RMSE': test_gradientboost_rmse_single,\n",
    "    'Test R²': test_gradientboost_r2_single,\n",
    "    'Test MBD': test_gradientboost_mbd_single,\n",
    "    'Test sMAPE': test_gradientboost_smape_single\n",
    "}\n",
    "\n",
    "# Metrics for Gradient Boosting Forecasting Model - Multi\n",
    "gb_forecast_metrics_multi = {\n",
    "    'Model': 'Gradient Boosting',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_gradientboost_mae_multi,\n",
    "    'Validation MSE': val_gradientboost_mse_multi,\n",
    "    'Validation MAPE': val_gradientboost_mape_multi,\n",
    "    'Validation RMSE': val_gradientboost_rmse_multi,\n",
    "    'Validation R²': val_gradientboost_r2_multi,\n",
    "    'Validation MBD': val_gradientboost_mbd_multi,\n",
    "    'Validation sMAPE': val_gradientboost_smape_multi,\n",
    "    'Test MAE': test_gradientboost_mae_multi,\n",
    "    'Test MSE': test_gradientboost_mse_multi,\n",
    "    'Test MAPE': test_gradientboost_mape_multi,\n",
    "    'Test RMSE': test_gradientboost_rmse_multi,\n",
    "    'Test R²': test_gradientboost_r2_multi,\n",
    "    'Test MBD': test_gradientboost_mbd_multi,\n",
    "    'Test sMAPE': test_gradientboost_smape_multi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Gradient Boosting Error Correction Model\n",
    "# gb_error_correction_metrics = {\n",
    "#     'Model': 'Gradient Boosting',\n",
    "#     'Task': 'Error Correction',\n",
    "#     'Validation MAE': val_corrected_gb_mae,\n",
    "#     'Validation MSE': val_corrected_gb_mse,\n",
    "#     'Validation MAPE': val_corrected_gb_mape,\n",
    "#     'Validation RMSE': val_corrected_gb_rmse,\n",
    "#     'Validation R²': val_corrected_gb_r2,\n",
    "#     'Validation MBD': val_corrected_gb_mbd,\n",
    "#     'Validation sMAPE': val_corrected_gb_smape,\n",
    "#     'Test MAE': test_corrected_gb_mae,\n",
    "#     'Test MSE': test_corrected_gb_mse,\n",
    "#     'Test MAPE': test_corrected_gb_mape,\n",
    "#     'Test RMSE': test_corrected_gb_rmse,\n",
    "#     'Test R²': test_corrected_gb_r2,\n",
    "#     'Test MBD': test_corrected_gb_mbd,\n",
    "#     'Test sMAPE': test_corrected_gb_smape\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for ARIMA model - Single\n",
    "arima_metrics_single = {\n",
    "    'Model': 'ARIMA',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_arima_mae_single,\n",
    "    'Validation MSE': val_arima_mse_single,\n",
    "    'Validation MAPE': val_arima_mape_single,\n",
    "    'Validation RMSE': val_arima_rmse_single,\n",
    "    'Validation R²': val_arima_r2_single,\n",
    "    'Validation MBD': val_arima_mbd_single,\n",
    "    'Validation sMAPE': val_arima_smape_single,\n",
    "    'Test MAE': test_arima_mae_single,\n",
    "    'Test MSE': test_arima_mse_single,\n",
    "    'Test MAPE': test_arima_mape_single,\n",
    "    'Test RMSE': test_arima_rmse_single,\n",
    "    'Test R²': test_arima_r2_single,\n",
    "    'Test MBD': test_arima_mbd_single,\n",
    "    'Test sMAPE': test_arima_smape_single\n",
    "}\n",
    "\n",
    "# Metrics for ARIMA model - Multi\n",
    "arima_metrics_multi = {\n",
    "    'Model': 'ARIMA',\n",
    "    # 'Task': 'Forecasting',\n",
    "    'Validation MAE': val_arima_mae_multi,\n",
    "    'Validation MSE': val_arima_mse_multi,\n",
    "    'Validation MAPE': val_arima_mape_multi,\n",
    "    'Validation RMSE': val_arima_rmse_multi,\n",
    "    'Validation R²': val_arima_r2_multi,\n",
    "    'Validation MBD': val_arima_mbd_multi,\n",
    "    'Validation sMAPE': val_arima_smape_multi,\n",
    "    'Test MAE': test_arima_mae_multi,\n",
    "    'Test MSE': test_arima_mse_multi,\n",
    "    'Test MAPE': test_arima_mape_multi,\n",
    "    'Test RMSE': test_arima_rmse_multi,\n",
    "    'Test R²': test_arima_r2_multi,\n",
    "    'Test MBD': test_arima_mbd_multi,\n",
    "    'Test sMAPE': test_arima_smape_multi\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics into a single DataFrame\n",
    "# all_metrics_df = pd.DataFrame([\n",
    "#     rf_forecast_metrics, rf_error_correction_metrics,\n",
    "#     gb_forecast_metrics, gb_error_correction_metrics\n",
    "# ])\n",
    "# all_metrics_df = pd.DataFrame([\n",
    "#     rf_forecast_metrics, \n",
    "#     gb_forecast_metrics\n",
    "# ])\n",
    "all_metrics_df_single = pd.DataFrame([\n",
    "    rf_forecast_metrics_single, \n",
    "    gb_forecast_metrics_single,\n",
    "    arima_metrics_single\n",
    "])\n",
    "\n",
    "all_metrics_df_multi = pd.DataFrame([\n",
    "    rf_forecast_metrics_multi, \n",
    "    gb_forecast_metrics_multi,\n",
    "    arima_metrics_multi\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "all_metrics_df_single.to_csv('model_comparison_metrics_single.csv', index=False)\n",
    "all_metrics_df_multi.to_csv('model_comparison_metrics_multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model names as the index - Single\n",
    "# all_metrics_df.set_index('Model', inplace=True)\n",
    "transposed_metrics_df_single = all_metrics_df_single.set_index('Model').T\n",
    "\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) \n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table plot\n",
    "tbl_single = table(ax, transposed_metrics_df_single, loc='center', cellLoc='center')\n",
    "\n",
    "# Save the table as an image\n",
    "plt.savefig('model_metrics_table_S.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Set the model names as the index - Multi\n",
    "transposed_metrics_df_multi = all_metrics_df_multi.set_index('Model').T\n",
    "# Plot the table\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) \n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table plot\n",
    "tbl_multi = table(ax, transposed_metrics_df_multi, loc='center', cellLoc='center')\n",
    "\n",
    "# Save the table as an image\n",
    "plt.savefig('model_metrics_table_S.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the saved metrics\n",
    "# loaded_metrics_df = pd.read_csv('model_comparison_metrics.csv')\n",
    "\n",
    "# # Filter data for plotting\n",
    "# # forecasting_metrics = loaded_metrics_df[loaded_metrics_df['Task'] == 'Forecasting']\n",
    "\n",
    "# # Normalize or log-scale MSE and RMSE to bring them to a comparable scale\n",
    "# # forecasting_metrics['Validation MSE'] = np.log1p(forecasting_metrics['Validation MSE'])\n",
    "# # forecasting_metrics['Validation RMSE'] = np.log1p(forecasting_metrics['Validation RMSE'])\n",
    "# # forecasting_metrics['Test MSE'] = np.log1p(forecasting_metrics['Test MSE'])\n",
    "# # forecasting_metrics['Test RMSE'] = np.log1p(forecasting_metrics['Test RMSE'])\n",
    "# # error_correction_metrics = loaded_metrics_df[loaded_metrics_df['Task'] == 'Error Correction']\n",
    "\n",
    "# # Plot comparison with values and save plots\n",
    "# def plot_metrics_comparison(df, task, filename):\n",
    "#     metrics = df.columns[2:]  # Exclude 'Model' and 'Task' columns\n",
    "#     models = df['Model']\n",
    "    \n",
    "#     x = np.arange(len(metrics))\n",
    "#     width = 0.25\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(14, 8))\n",
    "#     rects1 = ax.bar(x - width, df.iloc[0, 2:], width, label=models.iloc[0])\n",
    "#     rects2 = ax.bar(x, df.iloc[1, 2:], width, label=models.iloc[1])\n",
    "#     rects3 = ax.bar(x + width, df.iloc[2, 2:], width, label=models.iloc[2])\n",
    "\n",
    "#     ax.set_xlabel('Metrics')\n",
    "#     ax.set_ylabel('Values')\n",
    "#     ax.set_title(f'{task} Model Comparison: Random Forest vs Gradient Boosting vs Arima')\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.set_xticklabels(metrics, rotation=45, ha=\"right\")\n",
    "#     ax.legend()\n",
    "    \n",
    "#     # Annotate values on bars\n",
    "#     def annotate_bars(rects):\n",
    "#         for rect in rects:\n",
    "#             height = rect.get_height()\n",
    "#             ax.annotate(f'{height:.2f}',\n",
    "#                         xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                         xytext=(0, 3),  # 3 points vertical offset\n",
    "#                         textcoords=\"offset points\",\n",
    "#                         ha='center', va='bottom')\n",
    "\n",
    "#     annotate_bars(rects1)\n",
    "#     annotate_bars(rects2)\n",
    "#     annotate_bars(rects3)\n",
    "\n",
    "#     plt.savefig(filename)\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "# # Plot and save forecasting metrics comparison\n",
    "# plot_metrics_comparison(loaded_metrics_df, 'Forecasting', 'plots/fc_metrics_comparison.png')\n",
    "\n",
    "# # Plot and save error correction metrics comparison\n",
    "# # plot_metrics_comparison(error_correction_metrics, 'Error Correction', 'plots/ec_metrics_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap - Single\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(transposed_metrics_df_single, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Heatmap of Model Metrics Comparison - Single Year', fontsize=16)\n",
    "plt.xlabel('Metrics', fontsize=12)\n",
    "plt.ylabel('Models', fontsize=12)\n",
    "\n",
    "# Save the heatmap as an image\n",
    "plt.savefig('plots/model_metrics_heatmap_S.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Create a heatmap - Multi\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(transposed_metrics_df_multi, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Heatmap of Model Metrics Comparison - Multi Years', fontsize=16)\n",
    "plt.xlabel('Metrics', fontsize=12)\n",
    "plt.ylabel('Models', fontsize=12)\n",
    "\n",
    "# Save the heatmap as an image\n",
    "plt.savefig('plots/model_metrics_heatmap.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = transposed_metrics_df_single.div(transposed_metrics_df_single.sum(axis=1), axis=0)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "ax = df_normalized.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Set title and labels for the stacked bar chart\n",
    "plt.title('Stacked Bar Chart of Model Metrics', fontsize=16)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Proportion of Metrics', fontsize=12)\n",
    "\n",
    "# Save the stacked bar chart as an image\n",
    "plt.savefig('plots/model_metrics_stacked_bar_chart.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the stacked bar chart\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "df_normalized = transposed_metrics_df_multi.div(transposed_metrics_df_multi.sum(axis=1), axis=0)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "ax = df_normalized.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Set title and labels for the stacked bar chart\n",
    "plt.title('Stacked Bar Chart of Model Metrics', fontsize=16)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Proportion of Metrics', fontsize=12)\n",
    "\n",
    "# Save the stacked bar chart as an image\n",
    "plt.savefig('plots/model_metrics_stacked_bar_chart.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the stacked bar chart\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
